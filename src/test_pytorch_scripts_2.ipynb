{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T03:34:24.627276Z",
     "start_time": "2024-04-18T03:34:24.579804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(\n",
      "  original_name=MyModule\n",
      "  (conv1): Conv2d(original_name=Conv2d)\n",
      "  (conv2): Conv2d(original_name=Conv2d)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=MyModule\n",
       "  (conv1): Conv2d(original_name=Conv2d)\n",
       "  (conv2): Conv2d(original_name=Conv2d)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "        # torch.jit.trace produces a ScriptModule's conv1 and conv2\n",
    "        self.conv1 = torch.jit.trace(nn.Conv2d(1, 20, 5), torch.rand(1, 1, 16, 16))\n",
    "        self.conv2 = torch.jit.trace(nn.Conv2d(20, 20, 5), torch.rand(1, 20, 16, 16))\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = F.relu(self.conv1(input))\n",
    "        input = F.relu(self.conv2(input))\n",
    "        return input\n",
    "\n",
    "scripted_module = torch.jit.script(MyModule())\n",
    "print(scripted_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T03:34:29.707553Z",
     "start_time": "2024-04-18T03:34:25.535621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7.5513,  8.1656],\n",
      "        [ 8.9144, 11.2090]])\n",
      "--Return--\n",
      "None\n",
      "> \u001b[1;32mc:\\users\\zuolu\\appdata\\local\\temp\\ipykernel_25144\\2145007978.py\u001b[0m(17)\u001b[0;36mpython_only_fn\u001b[1;34m()\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"C:\\Users\\zuolu\\AppData\\Local\\Temp\\ipykernel_25144\\2145007978.py\", line 21, in forward\n    def forward(self, input):\n        if self.training:\n            self.python_only_fn(input)\n            ~~~~~~~~~~~~~~~~~~~ <--- HERE\n        return input * 99\nRuntimeError: BdbQuit: <EMPTY MESSAGE>\n\nAt:\n  d:\\miniconda3\\envs\\mlc\\lib\\bdb.py(154): dispatch_return\n  d:\\miniconda3\\envs\\mlc\\lib\\bdb.py(92): trace_dispatch\n  C:\\Users\\zuolu\\AppData\\Local\\Temp\\ipykernel_25144\\2145007978.py(17): python_only_fn\n  d:\\miniconda3\\envs\\mlc\\lib\\site-packages\\torch\\jit\\_recursive.py(1069): lazy_binding_method\n  d:\\miniconda3\\envs\\mlc\\lib\\site-packages\\torch\\nn\\modules\\module.py(1541): _call_impl\n  d:\\miniconda3\\envs\\mlc\\lib\\site-packages\\torch\\nn\\modules\\module.py(1532): _wrapped_call_impl\n  C:\\Users\\zuolu\\AppData\\Local\\Temp\\ipykernel_25144\\2145007978.py(26): <module>\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py(3508): run_code\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py(3448): run_ast_nodes\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py(3269): run_cell_async\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\async_helpers.py(129): _pseudo_sync_runner\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py(3064): _run_cell\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py(3009): run_cell\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\zmqshell.py(549): run_cell\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py(449): do_execute\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py(778): execute_request\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py(362): execute_request\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py(437): dispatch_shell\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py(534): process_one\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py(545): dispatch_queue\n  d:\\miniconda3\\envs\\mlc\\lib\\asyncio\\events.py(81): _run\n  d:\\miniconda3\\envs\\mlc\\lib\\asyncio\\base_events.py(1859): _run_once\n  d:\\miniconda3\\envs\\mlc\\lib\\asyncio\\base_events.py(570): run_forever\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\tornado\\platform\\asyncio.py(205): start\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelapp.py(739): start\n  d:\\miniconda3\\envs\\mlc\\lib\\site-packages\\traitlets\\config\\application.py(985): launch_instance\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel_launcher.py(18): <module>\n  d:\\miniconda3\\envs\\mlc\\lib\\runpy.py(87): _run_code\n  d:\\miniconda3\\envs\\mlc\\lib\\runpy.py(194): _run_module_as_main\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m scripted_module \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mscript(MyModule())\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(scripted_module\u001b[38;5;241m.\u001b[39msome_entry_point(torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mscripted_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\mlc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\mlc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"C:\\Users\\zuolu\\AppData\\Local\\Temp\\ipykernel_25144\\2145007978.py\", line 21, in forward\n    def forward(self, input):\n        if self.training:\n            self.python_only_fn(input)\n            ~~~~~~~~~~~~~~~~~~~ <--- HERE\n        return input * 99\nRuntimeError: BdbQuit: <EMPTY MESSAGE>\n\nAt:\n  d:\\miniconda3\\envs\\mlc\\lib\\bdb.py(154): dispatch_return\n  d:\\miniconda3\\envs\\mlc\\lib\\bdb.py(92): trace_dispatch\n  C:\\Users\\zuolu\\AppData\\Local\\Temp\\ipykernel_25144\\2145007978.py(17): python_only_fn\n  d:\\miniconda3\\envs\\mlc\\lib\\site-packages\\torch\\jit\\_recursive.py(1069): lazy_binding_method\n  d:\\miniconda3\\envs\\mlc\\lib\\site-packages\\torch\\nn\\modules\\module.py(1541): _call_impl\n  d:\\miniconda3\\envs\\mlc\\lib\\site-packages\\torch\\nn\\modules\\module.py(1532): _wrapped_call_impl\n  C:\\Users\\zuolu\\AppData\\Local\\Temp\\ipykernel_25144\\2145007978.py(26): <module>\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py(3508): run_code\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py(3448): run_ast_nodes\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py(3269): run_cell_async\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\async_helpers.py(129): _pseudo_sync_runner\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py(3064): _run_cell\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py(3009): run_cell\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\zmqshell.py(549): run_cell\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py(449): do_execute\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py(778): execute_request\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py(362): execute_request\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py(437): dispatch_shell\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py(534): process_one\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py(545): dispatch_queue\n  d:\\miniconda3\\envs\\mlc\\lib\\asyncio\\events.py(81): _run\n  d:\\miniconda3\\envs\\mlc\\lib\\asyncio\\base_events.py(1859): _run_once\n  d:\\miniconda3\\envs\\mlc\\lib\\asyncio\\base_events.py(570): run_forever\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\tornado\\platform\\asyncio.py(205): start\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelapp.py(739): start\n  d:\\miniconda3\\envs\\mlc\\lib\\site-packages\\traitlets\\config\\application.py(985): launch_instance\n  C:\\Users\\zuolu\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel_launcher.py(18): <module>\n  d:\\miniconda3\\envs\\mlc\\lib\\runpy.py(87): _run_code\n  d:\\miniconda3\\envs\\mlc\\lib\\runpy.py(194): _run_module_as_main\n\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @torch.jit.export\n",
    "    def some_entry_point(self, input):\n",
    "        return input + 10\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def python_only_fn(self, input):\n",
    "        # This function won't be compiled, so any\n",
    "        # Python APIs can be used\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.training:\n",
    "            self.python_only_fn(input)\n",
    "        return input * 99\n",
    "\n",
    "scripted_module = torch.jit.script(MyModule())\n",
    "print(scripted_module.some_entry_point(torch.randn(2, 2)))\n",
    "print(scripted_module(torch.randn(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T03:34:30.311158Z",
     "start_time": "2024-04-18T03:34:30.282159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.jit.ScriptFunction'>\n",
      "def foo(x: Tensor,\n",
      "    y: Tensor) -> Tensor:\n",
      "  _0 = bool(torch.gt(torch.max(x), torch.max(y)))\n",
      "  if _0:\n",
      "    r = x\n",
      "  else:\n",
      "    r = y\n",
      "  return r\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "@torch.jit.script\n",
    "def foo(x, y):\n",
    "    if x.max() > y.max():\n",
    "        r = x\n",
    "    else:\n",
    "        r = y\n",
    "    return r\n",
    "\n",
    "print(type(foo))  # torch.jit.ScriptFunction\n",
    "\n",
    "# See the compiled graph as Python code\n",
    "print(foo.code)\n",
    "\n",
    "# Call the function using the TorchScript interpreter\n",
    "foo(torch.ones(2, 2), torch.ones(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T03:34:30.826814Z",
     "start_time": "2024-04-18T03:34:30.811717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.jit.ScriptFunction'>\n",
      "def test_sum(a: Tensor,\n",
      "    b: Tensor) -> Tensor:\n",
      "  return torch.add(a, b)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.1167, 1.2970]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def test_sum(a, b):\n",
    "    return a + b\n",
    "\n",
    "# Annotate the arguments to be int\n",
    "scripted_fn = torch.jit.script(test_sum, example_inputs=[(3, 4)])\n",
    "\n",
    "print(type(scripted_fn))  # torch.jit.ScriptFunction\n",
    "\n",
    "# See the compiled graph as Python code\n",
    "print(scripted_fn.code)\n",
    "\n",
    "# Call the function using the TorchScript interpreter\n",
    "a= torch.rand(1,2)\n",
    "b= torch.rand(1,2)\n",
    "# scripted_fn(20, 100)\n",
    "scripted_fn(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T03:34:31.388082Z",
     "start_time": "2024-04-18T03:34:31.370981Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self, N, M):\n",
    "        super().__init__()\n",
    "        # This parameter will be copied to the new ScriptModule\n",
    "        self.weight = torch.nn.Parameter(torch.rand(N, M))\n",
    "\n",
    "        # When this submodule is used, it will be compiled\n",
    "        self.linear = torch.nn.Linear(N, M)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.weight.mv(input)\n",
    "\n",
    "        # This calls the `forward` method of the `nn.Linear` module, which will\n",
    "        # cause the `self.linear` submodule to be compiled to a `ScriptModule` here\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "scripted_module = torch.jit.script(MyModule(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T03:34:31.811206Z",
     "start_time": "2024-04-18T03:34:31.806467Z"
    }
   },
   "outputs": [],
   "source": [
    "print(scripted_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T03:34:32.295396Z",
     "start_time": "2024-04-18T03:34:32.251399Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # torch.jit.trace produces a ScriptModule's conv1 and conv2\n",
    "        self.conv1 = torch.jit.trace(nn.Conv2d(1, 20, 5), torch.rand(1, 1, 16, 16))\n",
    "        self.conv2 = torch.jit.trace(nn.Conv2d(20, 20, 5), torch.rand(1, 20, 16, 16))\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = F.relu(self.conv1(input))\n",
    "        input = F.relu(self.conv2(input))\n",
    "        return input\n",
    "\n",
    "scripted_module = torch.jit.script(MyModule())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T03:34:32.821540Z",
     "start_time": "2024-04-18T03:34:32.811539Z"
    }
   },
   "outputs": [],
   "source": [
    "print(scripted_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T03:34:33.289603Z",
     "start_time": "2024-04-18T03:34:33.260604Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.jit.trace for functions\n",
    "import torch\n",
    "\n",
    "def foo(x, y):\n",
    "    return 2 * x + y\n",
    "\n",
    "traced_foo = torch.jit.trace(foo, (torch.rand(3), torch.rand(3)))\n",
    "\n",
    "# torch.jit.trace for modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 1, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "n = Net()\n",
    "example_weight = torch.rand(1, 1, 3, 3)\n",
    "example_forward_input = torch.rand(1, 1, 3, 3)\n",
    "traced_module = torch.jit.trace(n, example_forward_input)\n",
    "\n",
    "print(traced_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T03:34:33.787949Z",
     "start_time": "2024-04-18T03:34:33.783945Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T03:35:26.408850Z",
     "start_time": "2024-04-18T03:35:26.353824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(\n",
      "  original_name=MyModule\n",
      "  (conv1): Conv2d(original_name=Conv2d)\n",
      "  (conv2): Conv2d(original_name=Conv2d)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "        # torch.jit.trace produces a ScriptModule's conv1 and conv2\n",
    "        self.conv1 = torch.jit.trace(nn.Conv2d(1, 20, 5), torch.rand(1, 1, 16, 16))\n",
    "        self.conv2 = torch.jit.trace(nn.Conv2d(20, 20, 5), torch.rand(1, 20, 16, 16))\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = F.relu(self.conv1(input))\n",
    "        input = F.relu(self.conv2(input))\n",
    "        return input\n",
    "\n",
    "scripted_module = torch.jit.script(MyModule())\n",
    "\n",
    "print(scripted_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting tabulate\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/40/44/4a5f08c96eb108af5cb50b41f76142f0afa346dfa99d5296fe7202a11854/tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip  install tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> my_compiler() invoked:\n",
      ">>> FX graph:\n",
      "opcode         name    target                   args          kwargs\n",
      "-------------  ------  -----------------------  ------------  --------\n",
      "placeholder    l_x_    L_x_                     ()            {}\n",
      "placeholder    l_y_    L_y_                     ()            {}\n",
      "call_function  add     <built-in function add>  (l_x_, l_y_)  {}\n",
      "call_function  mul     <built-in function mul>  (add, l_x_)   {}\n",
      "output         output  output                   ((mul,),)     {}\n",
      ">>> Code:\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, L_x_ : torch.Tensor, L_y_ : torch.Tensor):\n",
      "    l_x_ = L_x_\n",
      "    l_y_ = L_y_\n",
      "    add = l_x_ + l_y_;  l_y_ = None\n",
      "    mul = add * l_x_;  add = l_x_ = None\n",
      "    return (mul,)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "\n",
    "def my_compiler(gm: torch.fx.GraphModule, example_inputs: List[torch.Tensor]):\n",
    "    print(\">>> my_compiler() invoked:\")\n",
    "    print(\">>> FX graph:\")\n",
    "    gm.graph.print_tabular()\n",
    "    print(f\">>> Code:\\n{gm.code}\")\n",
    "    return gm.forward  # return a python callable\n",
    "\n",
    "@torch.compile(backend=my_compiler)\n",
    "def foo(x, y):\n",
    "    return (x + y) * x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    a, b = torch.randn(10), torch.ones(10)\n",
    "    foo(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "co_names ('print',)\n",
      "co_varnames ()\n",
      "co_consts (None, 'Hello, world!')\n",
      "  4           0 LOAD_GLOBAL              0 (print)\n",
      "              2 LOAD_CONST               1 ('Hello, world!')\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 POP_TOP\n",
      "              8 LOAD_CONST               0 (None)\n",
      "             10 RETURN_VALUE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import dis\n",
    "\n",
    "def hello():\n",
    "    print(\"Hello, world!\")\n",
    "\n",
    "for k in [\"co_names\", \"co_varnames\", \"co_consts\"]:\n",
    "    print(k, getattr(hello.__code__, k))\n",
    "print(dis.dis(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile(backend=my_compiler)\n",
    "def toy_example(x):\n",
    "    x = x / (torch.abs(x) + 1)\n",
    "    return x\n",
    "\n",
    "def test():\n",
    "    x = torch.randn(10)\n",
    "    toy_example(x)\n",
    "    x = torch.randn(20)\n",
    "    toy_example(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "model = models.resnet18().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "# compiled_model = torch. compile (model)   # 关键一行\n",
    "\n",
    "# reduce-overhead: optimizes to reduce the framework overhead\n",
    "#                and uses some extra memory. Helps speed up small models\n",
    "# torch.compile(model, mode=\"reduce-overhead\")\n",
    "\n",
    "# max-autotune: optimizes to produce the fastest model,\n",
    "#               but takes a very long time to compile\n",
    "compiled_model=torch.compile(model, mode=\"max-autotune\")\n",
    "\n",
    "\n",
    "x = torch.randn(16, 3, 224, 224).cuda()\n",
    "optimizer.zero_grad()\n",
    "out = compiled_model(x)\n",
    "out.sum().backward()\n",
    "\n",
    "optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "exported_model = torch._dynamo.export(model, input)\n",
    "torch.save(exported_model, \"foo.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"foo.pt\")\n",
    "# both these lines of code do the same thing\n",
    "torch.save(model.state_dict(), \"foo.pt\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
